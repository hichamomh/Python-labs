{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 2 - Practise with classic libraries\n",
    "\n",
    "Students (pair):\n",
    "- [Student 1]([link](https://github.com/username1))\n",
    "- [Student 2]([link](https://github.com/username2))"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda create --name=lab2 --file=requirement.txt\n",
    "conda activate lab2\n",
    "# do not forget to deactivate the environment if needed\n",
    "# you can remove the environment once you are done\n",
    "conda env remove --name=lab2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful references for this lab**:\n",
    "\n",
    "[1] `numpy`: [lecture notes (1.4.1-1.4.2)](https://scipy-lectures.org/intro/numpy/index.html) and [documentation](https://numpy.org/doc/stable/)\n",
    "\n",
    "[2] `pandas`: [documentation](https://pandas.pydata.org/docs/getting_started/index.html), [quick tutorial](https://pandas.pydata.org/pandas-docs/version/0.15/10min.html)\n",
    "\n",
    "[3] `matplotlib`: [lecture notes (1.5)](https://scipy-lectures.org/intro/matplotlib/index.html) and [documentation](https://matplotlib.org/)\n",
    "\n",
    "[4] `h5py`: [quick start guide](http://docs.h5py.org/en/stable/quick.html#quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"content\">Contents</a>\n",
    "- [Exercise 1: Computing basic statistics](#ex1)\n",
    "- [Exercise 2: Random variables and histograms](#ex2)\n",
    "- [Exercise 3: Discrete isotropic total variation](#ex3)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"ex1\">Exercise 1: Random variables and histograms</a>\n",
    "\n",
    "In this exercise, we are interested in generating samples from the Gamma distribution $\\mathcal{G}(\\alpha,\\beta)$, of probability density function (pdf)\n",
    "\n",
    "\\begin{equation}\n",
    "    p(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} \\exp(-\\beta x) \\mathbb{1}_{\\mathbb{R}_+^*}(x),\n",
    "\\end{equation}\n",
    "\n",
    "and displaying their histogram. In the following, we consider $(\\alpha, \\beta) = (9, 2)$.\n",
    "\n",
    "1\\. Set the random seed to a fixed value for reproducibility, and biefly check your instruction works as intended.\n",
    "> Hint: you may take a look at the following pages: [random module](https://numpy.org/doc/stable/reference/random/index.html?highlight=random#module-numpy.random), [random generator](https://numpy.org/doc/stable/reference/random/generator.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Generate $\\approx 10^5$ samples in a vector. Save the vector in a file, `samples.hdf5` or `samples.npy`.\n",
    "> Warning / hint: \n",
    "> - take a careful look at the [documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.gamma.html?highlight=gamma#numpy.random.gamma) (multiple conventions exist for the definition of the pdf underlying the distribution...);\n",
    "> - to save data in a `npy` file, take a look at the example reported in the [Numpy documentation](https://numpy.org/doc/stable/reference/generated/numpy.save.html);\n",
    "> - to save data in a `.h5` file, take a quick look at the [documentation here](https://docs.h5py.org/en/stable/quick.html#quick)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Estimate an histogram of this distribution for a well chosen set of bins, and display it.\n",
    "> Warnings: \n",
    "> - make sure the [histogram](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html?highlight=hist#matplotlib.pyplot.hist) corresponds to a probability density function (pdf);\n",
    "> - do not forget to include a proper title with names for the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Overlay the probability density function on the histogram and compare these in a few words. Save the resulting picture in `.png` format.\n",
    "> Hint: \n",
    "> - take a look at the `scipy` [documentation](https://docs.scipy.org/doc/scipy/reference/stats.html) to avoid implementing the pdf from scratch;\n",
    "> - return the bins in which the histogram is computed, and evaluate the pdf on those points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"ex2\">Exercise 2: Basic statistics with `pandas`</a>\n",
    "\n",
    "In this second exercise, we focus on computing basic statistics, and applying linear regression to a small data set. These data are gathered in the following table, which gives the infant mortality (`X`) and the gross national product per inhabitant (`Y`) of 12 european countries :\n",
    "\n",
    "| `X` | 190 | 128 | 180 | 212 | 56 | 192 | 68 | 98 | 110 | 197 | 181 | 233 |\n",
    "|-----|-----|-----|-----|----|-----|----|----|-----|-----|-----|-----|-----|\n",
    "| `Y` |  24 |  28 |  24 | 19 |  37 | 22 | 34 |  25 |  36 |  24 |  20 |  18 |\n",
    "\n",
    "1\\. For `X `and `Y`, compute the median, mean, variance and standard deviation. The data points have already been entered into a `.csv` file stored in `data/data.csv`.\n",
    "> Hint: \n",
    "> - you can directly use `pandas` to load the data into a `DataFrame` ([`pd.read_csv`](https://pandas.pydata.org/docs/reference/frame.html));\n",
    "> - take a look at the built-in operations available for `DataFrame` objects ([documentation](https://pandas.pydata.org/docs/reference/frame.html));\n",
    "> - to display a `DataFrame` `f`:\n",
    "> ```python \n",
    "> from IPython.display import display\n",
    "> display(df)\n",
    "> ```\n",
    "> - sort the `DataFrame` with respect to the value of `X` (see [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)) This will be useful for question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Give the equation of the regression line of `Y` as a function of `X`.\n",
    "> Hint: \n",
    "> - take a look at the functionalities available in `numpy` (e.g., `np.polyfit` and `np.polyval`);\n",
    "> - if needed, note that you can retrieve the data from the resulting `pandas` `DataFrame` with the `to_numpy()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Display the cloud of points and the regression line $Y = f(X)$ on the same figure. Save the figure in `.png` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"ex3\">Exercise 3: Discrete isotropic total variation</a>\n",
    "\n",
    "This exercise is devoted to the computation of the discrete isotropic total variation (TV) of an input matrix $\\mathbf{X} = [\\mathbf{x}_n]_{1 \\leq n \\leq N} \\in\\mathbb{C}^{M \\times N}$, which is particularly useful in Bayesian inference (e.g., for inverse problems) to promote piece-wise smooth solutions. The TV is defined as\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\text{TV}(\\mathbf{X}) = \\Vert D(\\mathbf{X}) \\Vert_{1,2} = \\sum_{m=1}^M \\sum_{n=1}^N \\sqrt{[\\mathbf{XD}_h]^2_{m,n} + [\\mathbf{D}_v\\mathbf{X}]^2_{m,n}},\n",
    "\\end{equation*}\n",
    "\n",
    "where $[\\mathbf{Z}]_{m,n}$ denotes the elements in position $(m,n)$ of the matrix $\\mathbf{Z}$,\n",
    "\n",
    "\\begin{align*}\n",
    "    D(X) &= (\\mathbf{XD}_h, \\mathbf{D}_v\\mathbf{X}) \\in \\mathbb{C}^{M\\times N} \\times \\mathbb{C}^{M\\times N} \\\\\n",
    "    %\n",
    "    \\mathbf{XD}_h &= [\\mathbf{x}_2-\\mathbf{x}_1, \\dotsc, \\mathbf{x}_N-\\mathbf{x}_{N-1}, \\mathbf{0}_M] \\in \\mathbb{C}^{M\\times N} \\\\\n",
    "    %\n",
    "    \\mathbf{D}_v\\mathbf{X} &= [\\tilde{\\mathbf{x}}_2^T-\\tilde{\\mathbf{x}}^T_1, \\dotsc, \\tilde{\\mathbf{x}}^T_M-\\tilde{\\mathbf{x}}^T_{M-1}, \\mathbf{0}_N]^T \\in \\mathbb{C}^{M\\times N},\n",
    "\\end{align*}\n",
    "\n",
    "$\\mathbf{x}_n \\in \\mathbb{C}^{M}$ is the $n$-th column of $\\mathbf{X}$, and $\\tilde{\\mathbf{x}}_m \\in \\mathbb{C}^{1\\times N}$ is the $m$-th row of $\\mathbf{X}$. \n",
    "The linear operator $D: \\mathbb{C}^{M\\times N} \\rightarrow \\mathbb{C}^{M\\times N} \\times \\mathbb{C}^{M\\times N} $ is the discrete gradient operator. The adjoint of $D$, $D^*: \\mathbb{C}^{M\\times N} \\times \\mathbb{C}^{M\\times N} \\rightarrow \\mathbb{C}^{M\\times N}$, is given by\n",
    "\n",
    "\\begin{align*}\n",
    "    (\\forall \\mathbf{Y} = (\\mathbf{Y}_h,\\mathbf{Y}_v)), \\quad D^*(\\mathbf{Y}) &= \\mathbf{Y}_h\\mathbf{D}^*_h + \\mathbf{D}^*_v\\mathbf{Y}_v \\\\\n",
    "    %\n",
    "    \\mathbf{Y}_h\\mathbf{D}^*_h &= \\big[-\\mathbf{y}_{h,1},- [\\mathbf{y}_{h,n}-\\mathbf{y}_{h,n-1}]_{2 \\leq n \\leq N-1}, \\mathbf{y}_{h, N-1} \\big] \\\\\n",
    "    %\n",
    "    \\mathbf{D}^*_v\\mathbf{Y}_v &= \\big[-\\tilde{\\mathbf{y}}_{v,1}^T,- [\\tilde{\\mathbf{y}}_{v,m}^T-\\tilde{\\mathbf{y}}^T_{v,m-1}]_{2 \\leq m \\leq M-1}, \\tilde{\\mathbf{y}}^T_{v, M-1} \\big]^T\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{y}_{h,n}$ is the $n$-th column of $\\mathbf{Y}_h$, and $\\tilde{\\mathbf{x}}_{v,m}$ is the $m$-th row of $\\mathbf{Y}_v$.\n",
    "\n",
    "1\\. Using `numpy`, implement a function `gradient2D` to compute the 2D discrete gradient operator $D$ applied to a matrix $\\mathbf{X}\\in\\mathbb{C}^{M \\times N}$ (no for loops!). Trigger an error message whenever the input array has more than 2 dimensions. If not clear from the implementation, add a few short comments to explain your code.\n",
    "\n",
    "> Hint: \n",
    "> - to trigger an error, you can for instance use an `assert` statement, or raise an [exception (e.g., `AssertionError`)](https://docs.python.org/3/library/exceptions.html);\n",
    "> - only a few operations are needed: computing vertical differences, horizontal differences, and possibly a concatenation of matrices into a single tensor (= n-dimensional array);\n",
    "> - possibly useful functions: `np.diff`, `np.c_`, `np.r_` (or `np.concatenate`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Implement a unit-test to validate the behaviour of the `gradient2D` function. For instance, you can check the format of the output, and test the result when the function is evaluated on a constant matrix (for both a square and a non-square input matrix). Run the unit-test from the present Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Document the function `gradient2D` with an appropriate docstring (see Lab 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using 1., define a function `tv` to compute $\\text{TV}(\\mathbf{X})$, $\\mathbf{X}\\in\\mathbb{C}^{M \\times N}$. Write a unit-test and document your function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Implement a function `gradient2D_adjoint` to compute $D^*(\\mathbf{Y})$, the adjoint of the 2D discrete gradient operator $D$ applied to $\\mathbf{Y}\\in\\mathbb{C}^{M \\times N}\\times \\mathbb{C}^{M \\times N}$. Add a few short comments to explain your code whenever appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Implement a unit-test to validate `gradient2D_adjoint`, e.g., by checking the size of the output from the function and verifying that `gradient2D_adjoint` is adjoint to `gradient2D`, i.e., for any $\\mathbf{X}\\in\\mathbb{C}^{M \\times N}$ and $\\mathbf{Y}\\in\\mathbb{C}^{M \\times N}\\times \\mathbb{C}^{M \\times N}$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\forall \\mathbf{X} \\in \\mathbb{C}^{M \\times N}, \\mathbf{Y} = (\\mathbf{Y}_h, \\mathbf{Y}_v) \\in \\mathbb{C}^{M \\times N} \\times \\mathbb{C}^{M \\times N}, \\;\n",
    "    %\n",
    "    \\langle D(\\mathbf{X}), \\mathbf{Y} \\rangle_{\\mathbb{C}^{M \\times N} \\times \\mathbb{C}^{M \\times N}} = \\langle \\mathbf{X}, D^*(\\mathbf{Y}) \\rangle_{\\mathbb{C}^{M \\times N}}, \n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align}\n",
    "    &\\forall \\mathbf{U}, \\mathbf{V} \\in \\mathbb{C}^{M \\times N}, \\; \\langle \\mathbf{U}, \\mathbf{V} \\rangle_{\\mathbb{C}^{M \\times N}} = \\text{Tr}(\\mathbf{U}^T \\mathbf{V}) = \\sum_{m=1}^M \\sum_{n=1}^N u_{m,n}^* v_{m,n}, \\\\\n",
    "    &\\forall \\mathbf{U} = (\\mathbf{U}_h, \\mathbf{U}_v), \\mathbf{V} = (\\mathbf{V}_h, \\mathbf{V}_v) \\in \\mathbb{C}^{M \\times N} \\times \\mathbb{C}^{M \\times N}, \\; \\langle \\mathbf{U}, \\mathbf{V} \\rangle_{\\mathbb{C}^{M \\times N} \\times \\mathbb{C}^{M \\times N}} = \\langle \\mathbf{U}_h, \\mathbf{V}_h \\rangle_{\\mathbb{C}^{M \\times N}} + \\langle \\mathbf{U}_v, \\mathbf{V}_v \\rangle_{\\mathbb{C}^{M \\times N}}.\n",
    "\\end{align}\n",
    "\n",
    "> Hint: to verify `gradient2D_adjoint` is the adjoint of `gradient2D`, evaluate the scalar products above for randomly drawn matrices. Set the random generator to a known state for reproducibility (see [Exercise 1](#ex1)).",
"\n",   
"> `np.conj` is useful."
]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bonus, **optional**]. Generalize the `gradient2D` to any number of dimensions ($\\mathbf{X} \\in \\mathbb{C}^{N_1 \\times N_2 \\times \\dotsc \\times N_p}$), i.e., by returning tensors obtained by computing differences along each of its dimensions.\n",
    "> Hint: \n",
    "> - you may use a loops here, and/or list comprehension. Using slice objects (see [np.s_](https://numpy.org/doc/stable/reference/generated/numpy.s_.html?highlight=s_#numpy.s_) and [this page](https://stackoverflow.com/questions/24432209/python-index-an-array-using-the-colon-operator-in-an-arbitrary-dimension)) can be an interesting option.\n",
    ">\n",
    "> - the definition of the scalar product above can be extended to the case of tensors as follows:\n",
    "\\begin{equation}\n",
    "    \\mathbf{U}, \\mathbf{V} \\in \\mathbb{C}^{N_1 \\times N_2 \\times \\dotsc \\times N_p}, \\; \\langle \\mathbf{U}, \\mathbf{V} \\rangle_{\\mathbb{C}^{N_1 \\times N_2 \\times \\dotsc \\times N_p}} =  \\sum_{n_1 = 1}^{N_1}  \\sum_{n_2 = 1}^{N_2} \\dotsc \\sum_{n_p = 1}^{N_p} u_{n_1, n_2, \\dotsc, n_p}^* v_{n_1, n_2, \\dotsc, n_p}   \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "```bibtex\n",
    "@article{condat:hal-01309685,\n",
    "  TITLE = {{Discrete Total Variation: New Definition and Minimization}},\n",
    "  AUTHOR = {Condat, Laurent},\n",
    "  URL = {https://hal.archives-ouvertes.fr/hal-01309685},\n",
    "  JOURNAL = {{SIAM Journal on Imaging Sciences}},\n",
    "  PUBLISHER = {{Society for Industrial and Applied Mathematics}},\n",
    "  VOLUME = {10},\n",
    "  NUMBER = {3},\n",
    "  PAGES = {1258--1290},\n",
    "  YEAR = {2017},\n",
    "  MONTH = Aug,\n",
    "  DOI = {10.1137/16M1075247},\n",
    "  KEYWORDS = { variational image processing ; total variation ;  finite-difference schemes ;  coarea formula},\n",
    "  PDF = {https://hal.archives-ouvertes.fr/hal-01309685v3/file/Condat-newTV.pdf},\n",
    "  HAL_ID = {hal-01309685},\n",
    "  HAL_VERSION = {v3},\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
