{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Session 6 - scraping the web with urllib3 and beautifulsoup\n",
    "\n",
    "Students (pair):\n",
    "- [Student 1]([link](https://github.com/username1))\n",
    "- [Student 2]([link](https://github.com/username2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful references for this lab**:\n",
    "\n",
    "[1] `urllib3`: [documentation](https://urllib3.readthedocs.io/en/latest/)\n",
    "\n",
    "[2] `beautifulsoup4`: [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) \n",
    "\n",
    "\n",
    "## <a name=\"content\">Contents</a>\n",
    "- [Exercise 1: Parsing the content of a web page](#ex1)\n",
    "- [Exercise 2: Extracting information from Wikipedia](#ex2)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook is aimed at introducing Python functions and library to automatically collect data from static web pages. In particular, this session will be devoted to the `urllib3` and `Beautiful Soup` packages.\n",
    "\n",
    " Other useful packages in this context:\n",
    " - `os` & `sys` to issue system instructions;\n",
    " - `re` for [**r**egular **e**xpressions when manipulating text strings](https://docs.python.org/3/library/re.html). The test the validity of a regular expression;\n",
    " - `datetime` to interact with dates & times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import date, datetime\n",
    "\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To take Centrale Lille's proxy into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If proxy : to get out through Centrale Lille's proxy\n",
    "centrale_proxy = False\n",
    "if centrale_proxy:\n",
    "    proxy = urllib3.ProxyManager(\"http://cache.ec-lille.fr:3128\")\n",
    "else:\n",
    "    proxy = urllib3.PoolManager()\n",
    "\n",
    "# See https://stackoverflow.com/questions/40490187/get-proxy-address-on-auto-proxy-discovery-mode-on-mac-os-x\n",
    "# scutil --proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex1\">Exercise/example 1: parsing the content of a web page</a> [(&#8593;)](#content)\n",
    "\n",
    "This example consits in retrieving the version number of the Beautiful Soup package, appearing in the top left corner of the associated [documentation webpage](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). To do this, you can for isntance use the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib3.request import urlopen\n",
    "response = proxy.request(\n",
    "    \"GET\", \"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Transform content into formatted text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8_text = response.data.decode(\"utf-8\")\n",
    "# print(utf8_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Look for the version number and print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful Soup 4.9.0\n"
     ]
    }
   ],
   "source": [
    "# Search data using Regex (regular expressions)\n",
    "# Test regex http://regexr.com\n",
    "regex = \"Beautiful Soup (\\d\\.){2}(\\d)\"  # looking for version number under the form Beautiful Soup 4.9.0\n",
    "web_text = re.search(regex, utf8_text)\n",
    "print(web_text.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Extract only the version number from the same page.\n",
    "\n",
    "> Hint: two useful pages about regular expressions (regexp): [tutorial](https://www.lucaswillems.com/fr/articles/25/tutoriel-pour-maitriser-les-expressions-regulieres), [verifying validity of an expression](http://regexr.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Take a look at the quickstart page of [`Beautiful Soup` (bs4 package)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), and use this library to retrieve the same information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hint:\n",
    "> - [this page on Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) can be useful\n",
    "> - useful elements of code:\n",
    ">\n",
    ">```python\n",
    "> from bs4 import BeautifulSoup\n",
    "> html_doc = proxy.request('GET','https://www.crummy.com/software/BeautifulSoup/bs4/doc/')\n",
    "> soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "> ...\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex2\">Exercise 2: Extracting information from Wikipedia</a> [(&#8593;)](#content)\n",
    "\n",
    "This exercise consists in extracting the birthdate of a list of actors from their Wikipedia page to infer their age. Consider for instance a list composed of Brad Pitt, Laurent Cantet, Jean-Paul Belmondo, Matthew McConaughey, Marion Cotillard, ...\n",
    "\n",
    "To this aim, take a look at one such Wikipedia page, verify whether a birthdate is reported, and take a look at the `.html` source code of the page (from your browser) to see where this information is located. \n",
    "\n",
    "First write a function to automatically retrieve the birthdate of each actor in the list. In a second step, convert this information into a \"numerical date\" (see codes below) and compute the difference with the current date to estimate the actors' age.\n",
    "\n",
    "> Hints: \n",
    "> - note that the birth date is associated whith the class `class=\"nowrap date-lien bday\"` (check source code of the web page);\n",
    "> - useful object: `bs4.BeautifulSoup`, with its `find` method, see the [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/);\n",
    "> - you can create an `Actor` class to collect useful attributes (see [here](https://scipy-lectures.org/intro/language/oop.html?highlight=classes) and [there](https://docs.python.org/3/tutorial/classes.html) for more details on defining classes in Python).\n",
    "> \n",
    ">```python\n",
    ">class Actor:\n",
    ">    def __init__(self, firstname, name):\n",
    ">        self.name = name\n",
    ">        self.firstname = firstname\n",
    ">    ...\n",
    ">\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Codes: one possible way to translate words into a numerical date to compute an age is\n",
    ">```python\n",
    "># Parse data (replace month by number)\n",
    ">month = ['janvier', 'février', 'mars', 'avril', 'mai', 'juin', 'juillet', 'août', 'septembre', 'octobre', 'novembre', 'décembre']\n",
    ">month_number = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    ">\n",
    ">for i in range(0, 12):\n",
    ">    web_date = web_date.replace(month[i], month_number[i])\n",
    ">    \n",
    "># Parse data and find the date to translate it into a numerical value\n",
    ">born = datetime.strptime(web_date, '%m %Y')\n",
    ">now = date.today()\n",
    ">\n",
    "># Compute the age\n",
    ">age = now - born.date()\n",
    ">age.days / 356\n",
    ">\n",
    ">result = now.year - born.date().year - ((now.month, now.day) < (born.date().month, born.date().day))\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
